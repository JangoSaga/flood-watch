import csv
import pickle
import pandas as pd
import os

def load_model_and_data():
    """
    Load trained model and necessary data files
    """
    script_dir = os.path.dirname(__file__)
    project_root = os.path.dirname(script_dir)
    # Load cities coordinates
    cities_path = os.path.join(project_root,'data', 'cities.csv')
    cities = []
    with open(cities_path, 'r', encoding='UTF-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            try:
                city = row['city']
                lat = float(row['latitude'])
                lon = float(row['longitude'])
                cities.append([city, lat, lon])  # [city, lat, lon]
            except (KeyError, ValueError, TypeError):
                continue
    
    return cities

def get_7day_prediction_data():
    """
    Load 7-day predictions generated by enhanced_forecast.py
    """
    script_dir = os.path.dirname(__file__)
    project_root = os.path.dirname(script_dir)
    predictions_path = os.path.join(project_root, 'data', '7day_flood_predictions.csv')
    
    try:
        # Load 7-day predictions
        predictions_df = pd.read_csv(predictions_path)
        print(f"Loaded {len(predictions_df)} 7-day prediction records")
        print(f"Data covers {predictions_df['City'].nunique()} cities over {predictions_df['Date'].nunique()} days")
        
        # Convert to list format for processing
        plotting_data = []
        for _, row in predictions_df.iterrows():
            plotting_data.append([
                row['City'],
                row['Latitude'], 
                row['Longitude'],
                row['Date'],
                row['Weather_Precip'],
                row['Max_Reservoir_Fill'],
                row['Predicted_Flood_Risk'],
                row['Flood_Probability'],
                row.get('Risk_Category', 'Low'),  # New field
                row.get('Confidence', 'Low'),
                row.get('explanation', 'No explanation available')  # Handle missing explanation
            ])
        
        return plotting_data
        
    except FileNotFoundError:
        print("ERROR: 7-day predictions file not found!")
        print("Please run enhanced_forecast.py first to generate predictions.")
        return []
    except Exception as e:
        print(f"Error loading 7-day predictions: {e}")
        return []

def create_plotting_csv(plotting_data):
    """
    Create CSV file for map visualization with 7-day data including risk categories
    """
    script_dir = os.path.dirname(__file__)
    project_root = os.path.dirname(script_dir)
    
    # Create data directory if it doesn't exist
    data_dir = os.path.join(project_root, 'data')
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
    
    output_path = os.path.join(data_dir, 'final_plot.csv')
    
    headers = [
        'City', 'Latitude', 'Longitude', 'Date', 'Precipitation', 
        'Max_Reservoir_Fill', 'Flood_Risk', 'Flood_Probability',
        'Risk_Category', 'Confidence', 'explanation'
    ]
    
    with open(output_path, 'w', newline='', encoding='UTF-8') as f:
        writer = csv.writer(f)
        writer.writerow(headers)
        writer.writerows(plotting_data)
    
    print(f"Created plotting data with {len(plotting_data)} city-day records")
    print(f"Saved to: {output_path}")

def generate_risk_summary(plotting_data):
    """
    Generate comprehensive summary of 7-day flood risk predictions with categories
    """
    if not plotting_data:
        print("No data to summarize")
        return
    
    # Define all 11 column names to match the data structure
    df = pd.DataFrame(plotting_data, columns=[
        'City', 'Latitude', 'Longitude', 'Date', 'Precipitation', 
        'Max_Reservoir_Fill', 'Flood_Risk', 'Flood_Probability',
        'Risk_Category', 'Confidence', 'explanation'    
    ])
    
    total_predictions = len(df)
    high_risk_predictions = len(df[df['Flood_Risk'] == 1])
    unique_cities = df['City'].nunique()
    unique_days = df['Date'].nunique()
    
    print("\n" + "="*60)
    print("7-DAY FLOOD RISK ANALYSIS SUMMARY")
    print("="*60)
    print(f"Cities analyzed: {unique_cities}")
    print(f"Forecast period: {unique_days} days")
    print(f"Total city-day predictions: {total_predictions}")
    print(f"High risk predictions: {high_risk_predictions} ({high_risk_predictions/total_predictions*100:.1f}%)")
    
    # Risk category analysis
    risk_category_counts = df['Risk_Category'].value_counts()
    print(f"\nRISK CATEGORY DISTRIBUTION:")
    print("-" * 40)
    for category in ['Critical', 'High', 'Medium', 'Low']:
        count = risk_category_counts.get(category, 0)
        percentage = count / total_predictions * 100
        print(f"• {category:8} Risk: {count:4} predictions ({percentage:.1f}%)")
    
    # Confidence level analysis
    confidence_counts = df['Confidence'].value_counts()
    print(f"\nFORECAST CONFIDENCE LEVELS:")
    print("-" * 40)
    for confidence in ['High', 'Low']:
        count = confidence_counts.get(confidence, 0)
        percentage = count / total_predictions * 100
        days_range = "Days 1-3" if confidence == 'High' else "Days 4-7"
        print(f"• {confidence} Confidence ({days_range}): {count:4} predictions ({percentage:.1f}%)")
    
    # City-level risk analysis by category
    city_stats = df.groupby('City').agg({
        'Flood_Risk': 'sum',
        'Flood_Probability': 'mean',
        'Risk_Category': lambda x: (x == 'Critical').sum()
    }).rename(columns={'Risk_Category': 'Critical_Days'}).sort_values('Flood_Probability', ascending=False)
    
    print(f"\nTOP 10 HIGHEST RISK CITIES:")
    print("-" * 60)
    print(f"{'City':<25} | {'Avg Risk':<8} | {'High Days':<9} | {'Critical Days'}")
    print("-" * 60)
    for city, stats in city_stats.head(10).iterrows():
        high_risk_days = int(stats['Flood_Risk'])
        critical_days = int(stats['Critical_Days'])
        avg_prob = stats['Flood_Probability']
        print(f"{city:<25} | {avg_prob:>8.3f} | {high_risk_days:>9}/7 | {critical_days:>12}/7")
    
    # Daily trend analysis with categories
    daily_stats = df.groupby('Date').agg({
        'Flood_Risk': 'sum',
        'Flood_Probability': 'mean',
        'City': 'count',
        'Risk_Category': lambda x: (x == 'Critical').sum(),
        'Confidence': lambda x: (x == 'High').sum()
    }).rename(columns={
        'City': 'Total_Cities', 
        'Risk_Category': 'Critical_Cities',
        'Confidence': 'High_Confidence_Cities'
    })
    
    print(f"\nDAILY FORECAST BREAKDOWN:")
    print("-" * 80)
    print(f"{'Date':<12} | {'Risk Cities':<11} | {'Critical':<8} | {'Avg Prob':<8} | {'High Conf'}")
    print("-" * 80)
    for date, stats in daily_stats.iterrows():
        high_risk = int(stats['Flood_Risk'])
        critical = int(stats['Critical_Cities'])
        total = int(stats['Total_Cities'])
        avg_prob = stats['Flood_Probability']
        high_conf = int(stats['High_Confidence_Cities'])
        print(f"{date:<12} | {high_risk:>4}/{total:<6} | {critical:>8}/7 | {avg_prob:>8.3f} | {high_conf:>8}/7")

def create_risk_zones_data(plotting_data):
    """
    Create enhanced risk zones with categories and confidence levels
    """
    script_dir = os.path.dirname(__file__)
    project_root = os.path.dirname(script_dir)
    data_dir = os.path.join(project_root, 'data')
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
    
    output_path = os.path.join(data_dir, 'risk_zones.csv')
    
    risk_zones = []
    for city_data in plotting_data:
        city_name = city_data[0]
        lat = city_data[1]
        lon = city_data[2]
        date = city_data[3]
        precipitation = city_data[4]
        reservoir_fill = city_data[5]
        flood_risk = city_data[6]
        flood_probability = city_data[7]
        risk_category = city_data[8]
        confidence = city_data[9]
        explanation = city_data[10] if len(city_data) > 10 else "No explanation available"
        
        # Determine alert level based on risk category
        alert_level_map = {
            'Critical': 'RED',
            'High': 'ORANGE', 
            'Medium': 'YELLOW',
            'Low': 'GREEN'
        }
        alert_level = alert_level_map.get(risk_category, 'GREEN')
        
        # Determine primary risk factor based on data values
        if precipitation > 50 and reservoir_fill > 80:
            risk_factor = "Weather + Reservoir"
        elif precipitation > 50:
            risk_factor = "Heavy Rainfall"
        elif reservoir_fill > 80:
            risk_factor = "High Reservoir Levels"
        elif precipitation > 20:
            risk_factor = "Moderate Rainfall"
        elif reservoir_fill > 60:
            risk_factor = "Elevated Reservoir Levels"
        else:
            risk_factor = "Normal Conditions"
        
        risk_zones.append([
            city_name, lat, lon, date, risk_category, alert_level, risk_factor, 
            confidence, round(precipitation, 1), round(reservoir_fill, 1), 
            round(flood_probability, 3), int(flood_risk), explanation
        ])
    
    # Save risk zones data
    headers = [
        'City', 'Latitude', 'Longitude', 'Date', 'Risk_Level', 'Alert_Level', 'Primary_Risk_Factor',
        'Confidence', 'Precipitation_mm', 'Max_Reservoir_Fill_Percent', 'Flood_Probability', 'Binary_Risk', 'Explanation'
    ]
    
    with open(output_path, 'w', newline='', encoding='UTF-8') as f:
        writer = csv.writer(f)
        writer.writerow(headers)
        writer.writerows(risk_zones)
    
    print(f"Created enhanced 7-day risk zones data: {output_path}")

def create_daily_summary(plotting_data):
    """
    Create day-wise summary for 7-day forecast with categories and confidence
    """
    script_dir = os.path.dirname(__file__)
    project_root = os.path.dirname(script_dir)
    data_dir = os.path.join(project_root, 'data')
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
        
    output_path = os.path.join(data_dir, 'daily_summary.csv')
    
    # Use all 11 columns
    df = pd.DataFrame(plotting_data, columns=[
        'City', 'Latitude', 'Longitude', 'Date', 'Precipitation', 
        'Max_Reservoir_Fill', 'Flood_Risk', 'Flood_Probability',
        'Risk_Category', 'Confidence', 'explanation'
    ])
    
    # Group by date and calculate daily statistics
    daily_stats = df.groupby('Date').agg({
        'Flood_Risk': 'sum',
        'Flood_Probability': ['mean', 'max', 'min', 'count'],
        'Precipitation': 'mean',
        'Max_Reservoir_Fill': 'mean',
        'Risk_Category': lambda x: (x == 'Critical').sum(),
        'Confidence': lambda x: (x == 'High').sum()
    }).round(3)
    
    # Flatten column names
    daily_stats.columns = [
        'High_Risk_Cities', 'Avg_Flood_Probability', 'Max_Flood_Probability', 'Min_Flood_Probability',
        'Total_Cities', 'Avg_Precipitation', 'Avg_Reservoir_Fill',
        'Critical_Risk_Cities', 'High_Confidence_Cities'
    ]
    
    daily_stats.to_csv(output_path)
    print(f"Created enhanced daily summary: {output_path}")

def create_city_summary(plotting_data):
    """
    Create city-wise summary showing risk trend over 7 days with categories
    """
    script_dir = os.path.dirname(__file__)
    project_root = os.path.dirname(script_dir)
    data_dir = os.path.join(project_root, 'data')
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
        
    output_path = os.path.join(data_dir, 'city_summary.csv')
    
    # Use first 10 columns (exclude explanation for city summary)
    df = pd.DataFrame(plotting_data, columns=[
        'City', 'Latitude', 'Longitude', 'Date', 'Precipitation', 
        'Max_Reservoir_Fill', 'Flood_Risk', 'Flood_Probability',
        'Risk_Category', 'Confidence', 'explanation'
    ])
    
    # Drop explanation column for city summary as it's not needed for aggregation
    df = df.drop('explanation', axis=1)
    
    # Group by city and calculate statistics
    city_stats = df.groupby('City').agg({
        'Flood_Risk': 'sum',
        'Flood_Probability': ['mean', 'max', 'std'],
        'Precipitation': 'mean',
        'Max_Reservoir_Fill': 'mean',
        'Latitude': 'first',
        'Longitude': 'first',
        'Risk_Category': lambda x: (x == 'Critical').sum(),
        'Confidence': lambda x: (x == 'High').sum()
    }).round(3)
    
    # Flatten column names
    city_stats.columns = [
        'Total_High_Risk_Days', 'Avg_Flood_Probability', 'Peak_Flood_Probability', 
        'Risk_Variability', 'Avg_Precipitation', 'Avg_Reservoir_Fill',
        'Latitude', 'Longitude', 'Critical_Risk_Days', 'High_Confidence_Days'
    ]
    
    # Add overall risk category based on average probability
    city_stats['Overall_Risk_Category'] = city_stats['Avg_Flood_Probability'].apply(
        lambda x: 'Critical' if x >= 0.8 else 
                 'High' if x >= 0.6 else 
                 'Medium' if x >= 0.4 else 'Low'
    )
    
    # Sort by average flood probability
    city_stats = city_stats.sort_values('Avg_Flood_Probability', ascending=False)
    
    city_stats.to_csv(output_path)
    print(f"Created enhanced city-wise summary: {output_path}")

def main():
    """
    Main function to process 7-day flood predictions with enhanced risk categorization
    """
    print("Processing enhanced 7-day flood predictions for visualization...")
    
    # Load model and cities (for reference, though we use forecast data)
    cities = load_model_and_data()
    print(f"Loaded {len(cities)} cities for reference")
    
    # Get 7-day prediction data from enhanced_forecast.py
    plotting_data = get_7day_prediction_data()
    
    if not plotting_data:
        print("\nERROR: No 7-day prediction data available!")
        print("Please run enhanced_forecast.py first to generate the predictions.")
        print("The forecast script will create 7day_flood_predictions.csv with the required data.")
        return
    
    # Create all output files for visualization and analysis
    print("\nCreating enhanced visualization and analysis files...")
    
    # Create plotting CSV for map visualization
    create_plotting_csv(plotting_data)
    
    # Generate comprehensive risk summary with categories
    generate_risk_summary(plotting_data)
    
    # Create enhanced risk zones with alert levels and confidence
    create_risk_zones_data(plotting_data)
    
    # Create daily and city summaries with new metrics
    create_daily_summary(plotting_data)
    create_city_summary(plotting_data)
    
    print("\n" + "="*60)
    print("ENHANCED 7-DAY FLOOD PREDICTION PROCESSING COMPLETE!")
    print("="*60)
    print("Files created for visualization and analysis:")
    print("• final_plot.csv        - Main data with risk categories & confidence")
    print("• risk_zones.csv        - Enhanced risk zones with alert levels") 
    print("• daily_summary.csv     - Day-wise forecast with confidence metrics")
    print("• city_summary.csv      - City-wise analysis with risk categories")
    print("\nEnhancements include:")
    print("• Risk categorization: Critical/High/Medium/Low")
    print("• Confidence levels: High (Days 1-3) / Low (Days 4-7)")
    print("• Alert system integration: RED/ORANGE/YELLOW/GREEN")
    print("• Academic-ready metrics for performance evaluation")
    print("\nThese files support:")
    print("- Multi-level risk visualization on interactive maps")
    print("- Confidence-based emergency response planning")
    print("- Academic research and model validation")
    print("- Real-time alert system integration")

if __name__ == "__main__":
    main()